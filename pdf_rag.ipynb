{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDF RAG System with Vietnamese Language Support\n",
    "\n",
    "This notebook implements a Retrieval-Augmented Generation (RAG) system for PDF documents with support for Vietnamese language using:\n",
    "- LangChain for the RAG pipeline\n",
    "- Qdrant for vector storage\n",
    "- Google Gemini for embedding and generation\n",
    "- PyPDF and PyMuPDF for PDF processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Packages\n",
    "\n",
    "First, let's install all necessary packages:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\S4V\\rag-pipeline-langchain-qdrant\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# üîë  PLACEHOLDER CONFIG\n",
    "# -----------------------------\n",
    "import os\n",
    "\n",
    "# -- Google Gemini / Gemini 1.5-flash ‚Äì\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\", \"your_api_key\")\n",
    "# -- Jina AI Embeddings ‚Äì\n",
    "JINA_API_KEY = os.getenv(\"JINA_API_KEY\", \"your_api_key\")\n",
    "# Put the keys in env so downstream libs pick them up automatically\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "os.environ[\"JINA_API_KEY\"] = JINA_API_KEY\n",
    "# -----------------------------\n",
    "\n",
    "import tempfile\n",
    "import fitz  # PyMuPDF\n",
    "from typing import List\n",
    "import google.generativeai as genai\n",
    "\n",
    "# LangChain / LLM + Embeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.embeddings import JinaEmbeddings\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from langchain_qdrant import Qdrant, QdrantVectorStore, RetrievalMode\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Initialise Jina embeddings up-front so we can reuse them everywhere\n",
    "text_embeddings = JinaEmbeddings(\n",
    "    jina_api_key=JINA_API_KEY, model_name=\"jina-embeddings-v3\"\n",
    ")\n",
    "#Qdrant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF Processing Functions\n",
    "\n",
    "We'll implement enhanced PDF extraction with support for Vietnamese text using PyMuPDF (fitz):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Extract text from PDF with special handling for Vietnamese text.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        \n",
    "    Returns:\n",
    "        List of Document objects with text content and metadata\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    try:\n",
    "        # Open the PDF file using PyMuPDF\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "        \n",
    "        # Process each page\n",
    "        for page_num, page in enumerate(pdf_document):\n",
    "            # Extract text from the page with improved handling for Vietnamese characters\n",
    "            text = page.get_text(\"text\")\n",
    "            \n",
    "            # Skip empty pages\n",
    "            if not text.strip():\n",
    "                continue\n",
    "                \n",
    "            # Create a Document object with metadata\n",
    "            doc = Document(\n",
    "                page_content=text,\n",
    "                metadata={\n",
    "                    \"source\": pdf_path,\n",
    "                    \"page_number\": page_num + 1,\n",
    "                    \"total_pages\": len(pdf_document)\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "    \n",
    "    return documents\n",
    "\n",
    "def split_documents(documents: List[Document], chunk_size: int = 1024\n",
    "                    , chunk_overlap: int = 200) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Split documents into chunks for better processing.\n",
    "    \n",
    "    Args:\n",
    "        documents: List of Document objects\n",
    "        chunk_size: Size of each chunk in characters\n",
    "        chunk_overlap: Overlap between chunks in characters\n",
    "        \n",
    "    Returns:\n",
    "        List of Document objects split into chunks\n",
    "    \"\"\"\n",
    "    # Create a text splitter optimized for Vietnamese\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\", \",\", \" \", \"\"],\n",
    "        keep_separator=True\n",
    "    )\n",
    "    \n",
    "    # Split the documents\n",
    "    return text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract text from scaned PDF\n",
    "\n",
    "Implement scanned pdf to documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\S4V\\rag-pipeline-langchain-qdrant\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from typing import List, Literal, Optional\n",
    "from pdf2image import convert_from_path\n",
    "from langchain.docstore.document import Document\n",
    "import pytesseract\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "# poppler_path = r\"D:\\poppler\\Library\\bin\"  # ƒê·∫£m b·∫£o r·∫±ng Poppler ƒë√£ ƒë∆∞·ª£c c√†i ƒë√∫ng ƒë∆∞·ªùng d·∫´n\n",
    "\n",
    "def extract_scan_pdf(\n",
    "    pdf_path: str | Path,\n",
    "    *,\n",
    "    lang: str = \"vie\",\n",
    "    dpi: int = 300,\n",
    "    poppler_path: Optional[str] = None,\n",
    "    extra_tess_config: str = \"--psm 6\",\n",
    ") -> List[Document]:\n",
    "    \"\"\"\n",
    "    Chuy·ªÉn PDF ƒë∆∞·ª£c scan th√†nh list[Document] (LangChain).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pdf_path : str | Path\n",
    "        ƒê∆∞·ªùng d·∫´n PDF.\n",
    "    lang : str, default ``\"vie\"``\n",
    "        M√£ ng√¥n ng·ªØ Tesseract (c√≥ th·ªÉ 'vie', 'eng+vie', ‚Ä¶).\n",
    "    dpi : int, default 300\n",
    "        ƒê·ªô ph√¢n gi·∫£i xu·∫•t ·∫£nh; cao h∆°n ‚Üí OCR ch√≠nh x√°c h∆°n nh∆∞ng ch·∫≠m h∆°n.\n",
    "    poppler_path : str | None\n",
    "        ƒê∆∞·ªùng d·∫´n th∆∞ m·ª•c ch·ª©a binary `pdftoppm` n·∫øu kh√¥ng c√≥ trong PATH (Windows).\n",
    "    extra_tess_config : str\n",
    "        Tham s·ªë c·∫•u h√¨nh b·ªï sung cho Tesseract (v√≠ d·ª• `--oem 1`, `--psm 4`).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    List[Document]\n",
    "        M·ªói trang PDF th√†nh m·ªôt `Document(page_content, metadata)`.\n",
    "        Metadata g·ªìm `page` (b·∫Øt ƒë·∫ßu 1) v√† `source` (t√™n file).\n",
    "    \"\"\"\n",
    "    pdf_path = Path(pdf_path).expanduser().resolve()\n",
    "    if not pdf_path.exists():\n",
    "        raise FileNotFoundError(f\"Kh√¥ng t√¨m th·∫•y file: {pdf_path}\")\n",
    "\n",
    "    # 1) PDF ‚ûú h√¨nh ·∫£nh\n",
    "    print(\"Converting PDF to Image\")\n",
    "\n",
    "    poppler_path = r\"D:\\poppler\\Library\\bin\"\n",
    "    try:\n",
    "        images = convert_from_path(\n",
    "            pdf_path.as_posix(),\n",
    "            dpi=dpi,\n",
    "            poppler_path=poppler_path,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error converting PDF to images: {e}\")\n",
    "        return []\n",
    "\n",
    "    # 2) OCR t·ª´ng trang\n",
    "    print(\"OCR each Pages\")\n",
    "    docs: List[Document] = []\n",
    "    for idx, img in enumerate(tqdm(images, desc=\"üîç OCR pages\", unit=\"page\"), start=1):\n",
    "        try:\n",
    "            text = pytesseract.image_to_string(\n",
    "                img, lang=lang, config=extra_tess_config\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error OCR page {idx}: {e}\")\n",
    "            text = \"\"  # N·∫øu c√≥ l·ªói OCR, b·ªè qua trang n√†y\n",
    "\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=text,\n",
    "                metadata={\"page\": idx, \"source\": pdf_path.name},\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Store with Qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client.http.exceptions import UnexpectedResponse\n",
    "# gi·∫£ s·ª≠ b·∫°n ƒë√£ c√≥ `text_embeddings` v√† `Document`, `Qdrant` ƒë∆∞·ª£c import\n",
    "\n",
    "def create_vector_store(\n",
    "    documents: List[Document],\n",
    "    collection_name: str = \"vietnamese_book_pdf_vectors\",\n",
    "    recreate: bool = False,      # ‚Üê th√™m tu·ª≥ ch·ªçn\n",
    ") -> Qdrant:\n",
    "    \"\"\"\n",
    "    T·∫°o (ho·∫∑c t√°i s·ª≠ d·ª•ng) vector store Qdrant.\n",
    "    \n",
    "    Args:\n",
    "        documents: Danh s√°ch Document ƒë·ªÉ index\n",
    "        collection_name: T√™n collection trong Qdrant\n",
    "        recreate: True => xo√° & t·∫°o l·∫°i; False => d√πng collection c≈© n·∫øu ƒë√£ t·ªìn t·∫°i\n",
    "    \"\"\"\n",
    "    client = QdrantClient(url=\"http://localhost:6333\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1) Chu·∫©n b·ªã collection\n",
    "    # ------------------------------------------------------------------\n",
    "    try:\n",
    "        if recreate:\n",
    "            # Xo√° n·∫øu t·ªìn t·∫°i, r·ªìi t·∫°o m·ªõi\n",
    "            client.recreate_collection(\n",
    "                collection_name=collection_name,\n",
    "                vectors_config=VectorParams(size=1024, distance=Distance.COSINE),\n",
    "            )\n",
    "        else:\n",
    "            # Ch·ªâ t·∫°o n·∫øu CH∆ØA c√≥\n",
    "            if collection_name not in [\n",
    "                c.name for c in client.get_collections().collections\n",
    "            ]:\n",
    "                client.create_collection(\n",
    "                    collection_name=collection_name,\n",
    "                    vectors_config=VectorParams(size=1024, distance=Distance.COSINE),\n",
    "                )\n",
    "    except UnexpectedResponse as e:\n",
    "        # B·∫Øt l·ªói 409 nh∆∞ng ƒë·ªÉ c√°c l·ªói kh√°c n·ªïi l√™n\n",
    "        if getattr(e, \"status_code\", None) == 409:\n",
    "            # Collection ƒë√£ t·ªìn t·∫°i & recreate=False ‚Üí b·ªè qua\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2) Kh·ªüi t·∫°o Vector store v√† th√™m t√†i li·ªáu\n",
    "    # ------------------------------------------------------------------\n",
    "    vector_store = Qdrant(\n",
    "        client=client,\n",
    "        collection_name=collection_name,\n",
    "        embeddings=text_embeddings,\n",
    "    )\n",
    "    vector_store.add_documents(documents)\n",
    "    return vector_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure RAG Chain with Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚îÄ‚îÄ‚îÄ imports ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ ONE-SHOT QA (vector search + Gemini) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def answer_question(\n",
    "    vector_store,  # Qdrant (ho·∫∑c b·∫•t k·ª≥ VectorStore n√†o h·ªó tr·ª£ similarity_search)\n",
    "    question: str,  # c√¢u h·ªèi c·ªßa user\n",
    "    chat_history: list,  # list[BaseMessage] (HumanMessage / AIMessage)\n",
    "    k: int = 10,  # s·ªë chunk l·∫•y t·ª´ vector search\n",
    "):\n",
    "    \"\"\"\n",
    "    1. vector_store.similarity_search -> l·∫•y k ƒëo·∫°n context\n",
    "    2. Nh·ªìi context + l·ªãch s·ª≠ h·ªôi tho·∫°i v√†o prompt\n",
    "    3. G·ªçi Gemini-flash, tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi & c·∫≠p nh·∫≠t chat_history\n",
    "    \"\"\"\n",
    "\n",
    "    # 1Ô∏è‚É£  L·∫•y context --------------------------------------------------------\n",
    "    docs = vector_store.similarity_search(question, k=k)\n",
    "    context = \"\\n\\n\".join(d.page_content for d in docs) or \"Kh√¥ng c√≥ ng·ªØ c·∫£nh.\"\n",
    "\n",
    "    # 2Ô∏è‚É£  X√¢y prompt ---------------------------------------------------------\n",
    "    system_prompt = (\n",
    "        \"You are a helpful assistant answering from provided context. \"\n",
    "        \"If the question is in Vietnamese, answer in Vietnamese with full \"\n",
    "        \"diacritics. If the answer is not in the context, say you don't know.\\n\\n\"\n",
    "        f\"Context:\\n{context}\"\n",
    "    )\n",
    "\n",
    "    # Danh s√°ch message: System + l·ªãch s·ª≠ + c√¢u h·ªèi m·ªõi\n",
    "    messages = (\n",
    "        [SystemMessage(system_prompt)] + chat_history + [HumanMessage(content=question)]\n",
    "    )\n",
    "\n",
    "    # 3Ô∏è‚É£  G·ªçi Gemini ---------------------------------------------------------\n",
    "    llm = ChatGoogleGenerativeAI(\n",
    "        model=\"gemini-2.5-flash-preview-04-17\",\n",
    "        temperature=0.5,\n",
    "        additional_kwargs={\"generation_config\": {\"top_p\": 0.95, \"top_k\": 40}},\n",
    "    )\n",
    "    print(messages)\n",
    "    ai_msg: AIMessage = llm.invoke(messages)\n",
    "\n",
    "    # 4Ô∏è‚É£  C·∫≠p nh·∫≠t l·ªãch s·ª≠ & tr·∫£ v·ªÅ -----------------------------------------\n",
    "    chat_history.extend([HumanMessage(content=question), ai_msg])\n",
    "    return ai_msg.content  # ho·∫∑c return ai_msg n·∫øu b·∫°n c·∫ßn full object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Upload and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ  Processing: SGK_Toan9.pdf\n",
      "Converting PDF to Image\n",
      "OCR each Pages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üîç OCR pages: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 119/119 [04:34<00:00,  2.30s/page]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Extracted 119 pages\n",
      "- Split into 207 chunks\n",
      "\n",
      "‚úÖ  Ready for questions!\n"
     ]
    }
   ],
   "source": [
    "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "# ‚ïë  üöÄ  Build the index from a local PDF (no widget, no upload)   ‚ïë\n",
    "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "import os, tempfile, pathlib\n",
    "\n",
    "\n",
    "def build_index_from_local(pdf_path: str):\n",
    "    \"\"\"\n",
    "    Point to any local PDF, then extracts, chunks, embeds and\n",
    "    prepares the RAG chain.  Globals `vector_store` and `rag_chain`\n",
    "    are created exactly like before.\n",
    "    \"\"\"\n",
    "    pdf_path = pathlib.Path(pdf_path).expanduser().resolve()\n",
    "    if not pdf_path.exists():\n",
    "        raise FileNotFoundError(f\"{pdf_path} not found\")\n",
    "\n",
    "    print(f\"üìÑ  Processing: {pdf_path.name}\")\n",
    "\n",
    "    docs = extract_text_from_pdf(str(pdf_path))\n",
    "    if len(docs) == 0:\n",
    "        docs = extract_scan_pdf(str(pdf_path))\n",
    "    print(f\"- Extracted {len(docs)} pages\")\n",
    "    chunks = split_documents(docs)\n",
    "    print(f\"- Split into {len(chunks)} chunks\")\n",
    "\n",
    "    global vector_store\n",
    "    vector_store = create_vector_store(chunks)\n",
    "\n",
    "    print(\"\\n‚úÖ  Ready for questions!\")\n",
    "\n",
    "\n",
    "# ‚ñ∂Ô∏è  CHANGE THIS TO WHATEVER PDF YOU WANTh\n",
    "build_index_from_local(\"SGK_Toan9.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant answering from provided context. If the question is in Vietnamese, answer in Vietnamese with full diacritics. If the answer is not in the context, say you don\\'t know.\\n\\nContext:\\nkhi xu√¥ng d√¥c l√† 19 kmih.\\nSau b√†i h·ªçc n√†y, em ƒë√£ l√†m ƒë∆∞·ª£c nh·ªØng g√¨?\\n~ Gi·∫£i th√≠ch ƒë∆∞·ª£c m·ªôt s·ªë h·ªá th·ª©c v·ªÅ c·∫°nh v√† g√≥c trong tam gi√°c vu√¥ng (c·∫°nh g√≥c vu√¥ng\\nb·∫±ng c·∫°nh huy·ªÅn nh√†n v·ªõi sin g√≥c ƒë·ªëi ho·∫∑c nh√†n v·ªõi c√¥sin g√≥c k·ªÉ; c·∫°nh g√≥c vu√¥ng b·∫±ng\\nc·∫°nh g√≥c vu√¥ng c√≤n l·∫°i nh√¢n v·ªõi tang g√≥c ƒë·ªëi ho·∫∑c nh√¢n v·ªõi c√¥tang g√≥c k·ªÅ).\\n~ Gi·∫£i quy·∫øt ƒë∆∞·ª£c m·ªôt s·ªë v·∫•n ƒë·ªÅ th·ª±c ti·ªÖn g·∫Øn v·ªõi t·ªâ s·ªë l∆∞·ª£ng gi√°c c·ªßa g√≥c nh·ªçn (t√≠nh ƒë·ªô d√†i\\nƒëoan th·∫≥ng, ƒë·ªô l·ªõn g√≥c; √°p d·ª•ng gi·∫£i tam gi√°c vu√¥ng).\\n\\n` ma N HU·∫æ TU ch·∫ø ‚Äî‚Äú-.6·∫ø\"\"\\nPh·∫ßn HIVH H (V√Ä. | l) |\\nPh·∫ßn HIYH H·ª§U V√Ä I) LUUNG\\n|\\n0h∆∞∆°ng H·ªÜ TH·ª® L∆Ø·ª¢NG TR≈®NG\\nIRM B1RC WUDNG\\nTrong ch∆∞∆°ng n√†y, c√°c em s·∫Ω t√¨m hi·ªÉu v·ªÅ c√°c t√å s·ªë\\nl∆∞·ª£ng gi√°c c·ªßa q√≥c nh·ªçn l√† sin (sine), c√¥sin (cosine),\\ntang (tangent), c√¥tang (cotangent). C√°c em s·∫Ω h·ªçc c√°ch\\ns·ª≠ d·ª•ng t·ªâ s·ªë l∆∞·ª£ng gi√°c ƒë·ªÉ thi·∫øt l·∫≠p m·ªôt s·ªë h·ªá th·ª©c\\ngi·ªØa c·∫°nh v√† g√≥c trong tam gi√°c vu√¥ng, ƒë·ªìng th·ªùi\\nv·∫≠n d·ª•ng c√°c h·ªá th·ª©c tr√™n v√†o gi·∫£i tam gi√°c vu√¥ng\\n∆ë c≈©ng nh∆∞ gi·∫£i quy·∫øt m·ªôt s·ªë b√†i to√°n th·ª±c t·∫ø.\\nX ‚Äî ‚ÅÑ\\nVIH(MiII liUi QMI√ÅM /(4U ·ª• \"\\nT√Ø s√¥ l∆∞·ª£ng gi√°c c·ªßa g√≥c nh·ªçn gi√∫p ta c√≥ th·ªÉ t√≠nh ƒë∆∞·ª£c\\nkho·∫£ng c√°ch gi·ªØa hai ƒëi·ªÖm c√°ch xa nhau.\\n\\nC·ª• th√™ ƒë·ªìi v·ªõi tam gi√°c vu√¥ng ABC trong H√¨nh 3, ta c√≥:\\n.__ ‚Äî√ÅC b·ªã, AB c, A\\nsin≈ì=‚Äî‚Äî=‚Äî, tcos≈í≈ì=‚Äî‚Äî=-‚Äî;\\nBC a BC a\\nAC b AB c\\ntaa≈ì=‚Äî‚Äî=‚Äî; cot≈ì=‚Äî‚Äî=‚Äî. c b\\nAB ec AC b\\nC√Øiui √Ω: V·ªõi g√≥c nh·ªçn ∆°, ‚Ä†a c√≥:\\n¬´ 0< sn∆° < 1; 0 < cos∆° < 1. B a C\\n\"- H√¨nh 3\\ns CO[≈í = ‚Äî‚Äî.\\ntan≈ì\\nV√≠ d·ª• I. T√≠nh c√°c t·ªâ s·ªë l∆∞·ª£ng gi√°c c·ªßa g√≥c ≈ì trong tam gi√°c ABC (H√¨nh 4).\\nGi·∫£i C\\nX√©t tam gi√°c ABC, A = 90¬∞, B=∆°..\\nTa c√≥: 15\\nn∆° =^S=-< -√ø& tUSU ‚ÄúCC = <0‚Äù:\\nBC l≈† BC l¬ß\\n‚ÅÑ‚ÅÑ4) _\\ntnu= √Ç‚Ç¨ -.2 ~0 25, dc 2E. S, B 12 A\\nAB 12 AC 9 3 H√¨nh 4\\nTh·ª±c h√†nh 1. T√≠nh c√°c t·ªâ s·ªë l∆∞·ª£ng gi√°c c·ªßa g√≥c nh·ªçn A trong m·ªói tam gi√°c vu√¥ng ABC\\nc√≥ ·ªí = 90¬∞ ·ªü H√¨nh 5 (k·∫øt qu·∫£ l√†m tr√≤n ƒë·∫øn h√†ng ph·∫ßn trƒÉm).\\nA\\nk B\\nC\\nA\\nB 4 C Mu\\n8) b)\\nC\\nC B\\nNV\\n2\\n3\\nA B\\n‚Äúho\\nA\\nc) d)\\nH√¨nh $\\nV·∫≠n d·ª•ng 1. S·ª≠ d·ª•ng t·ªâ s·ªë l∆∞·ª£ng gi√°c ƒë·ªÉ gi·∫£i th√≠ch t√¨nh hu·ªëng trong ·∫æ)) (trang 60).\\n\\n2. GI·∫¢I TAM GI√ÅC VU√îNG\\n&; Cho tam gi√°c ABC (H√¨nh 5). Em h√£y cho bi·∫øt trong c√°c ·∫†\\ntr∆∞·ªùng h·ª£p n√†o sau ƒë√¢y, ta c√≥ th·ªÉ t√≠nh ƒë∆∞·ª£c t·∫•t c·∫£ c√°c ≈°\\nc·∫°nh v√† c√°c g√≥c c·ªßa tam gi√°c. Gi·∫£i th√≠ch c√°ch t√≠nh. ¬ß\\nB a C\\nH√¨nh 5\\n_T∆∞·ªùghp | 2a | b | c | ¬ß | √™ ‚Äî\\n‚Äù\"mmxm·∫Ω =mÀÜ RE. =\\nl·∫≤:z5|<:-.| ti mg iei<‚Äù..|. 5...\\nl5 | ‚Äî j_ |agiGi|ixisejs3e|- 1)\\nGi·∫£i m·ªôt tam gi√°c vu√¥ng l√† t√≠nh c√°c c·∫°nh v√† c√°c g√≥c c·ªßa tam gi√°c ƒë√≥.\\nT·ª´ ·ªî·ª≤, ta th·∫•y c√≥ th·ªÉ gi·∫£i ƒë∆∞·ª£c m·ªôt tam gi√°c vu√¥ng n·∫øu bi·∫øt hai c·∫°nh, ho·∫∑c m·ªôt c·∫°nh v√†\\nm·ªôt g√≥c nh·ªçn c·ªßa n√≥.\\nV√≠ d·ª• 3. Gi·∫£i c√°c tam gi√°c vu√¥ng ·ªü H√¨nh 6. L√†m tr√≤n k·∫øt qu·∫£ ƒë·ªô d√†i ƒë·∫øn h√†ng ƒë∆°n v·ªã v√†\\ns√¥ ƒëo g√≥c ƒë·ªÅn ƒë·ªô.\\nR\\nD\\nB +\\n√¨ ·ªç 13 9\\nP II\\nA √àb Ft √≥ P\\na) b) c)\\nH√¨nh 6\\nGi·∫£i\\na) X√©t tam gi√°c ABC vu√¥ng t·∫°i A, ta c√≥:\\nsinC=S ~.6, suy ra ‚Ç¨ s33\", √ñ ≈ì 90¬∞‚Äî33¬∞= 57,\\nBC II\\nTheo ƒë·ªãnh l√≠ Pythagore, ta c√≥:\\nAC=∆íBC? - AB? =x/11?‚Äî6? =4(121‚Äî36 s9.\\nb) X√©t tam gi√°c DEF vu√¥ng t·∫°i D, ta c√≥:\\nF =90¬∞‚Äî 32¬∞ = 589,\\nDE = DF. cot E =9. cot 32¬∞ 14;\\nsinE = D·ªÄ n√™n EF=-C.~_‚Äî 2_‚Äî 17.\\nEF snE sin32¬∞\\n\\ncot≈ì\\nTh·ª±c h√†nh 4.\\na) S·ª≠ ƒë·ª•ng m√°y t√≠nh c·∫ßm tay, t√≠nh t·ªâ s·ªë l∆∞·ª£ng gi√°c c·ªßa c√°c g√≥c sau (k·∫øt qu·∫£ l√†m tr√≤n ƒë·∫øn\\n` √Ä\\n\\nh√†ng ph√¢n ngh√¨n):\\nTnP 2 52¬∞- 1S20: 52\\'18\\'.\\nb) T√¨m c√°c g√≥c nh·ªçn x, y, Z, t trong m·ªói tr∆∞·ªùng h·ª£p sau (k·∫øt qu·∫£ l√†m tr√≤n ƒë·∫øn h√†ng\\nph√¢n trƒÉm ho·∫∑c ƒë·∫øn ph√∫t):\\nsinx= 0,723; cos y = 0,828; tan z= 3,77; cot t= 1,54.\\nV·∫≠n d·ª•ng 4.\\na) V·∫Ω m·ªôt tam gi√°c vu√¥ng c√≥ m·ªôt g√≥c b·∫±ng 40¬∞. ƒêo ƒë·ªô ƒë√†i c√°c c·∫°nh r·ªìi d√πng c√°c s√¥ ƒëo\\nƒë·ªÉ t√≠nh c√°c t·ªâ s·ªë l∆∞·ª£ng gi√°c c·ªßa g√≥c 40¬∞. Ki·ªÉm tra l·∫°i c√°c k·∫øt qu·∫£ v·ª´a t√≠nh b·∫±ng m√°y t√≠nh\\nc·∫ßm tay.\\nb) V·∫Ω m·ªôt tam gi√°c vu√¥ng c√≥ ba c·∫°nh b·∫±ng 3 em, 4 em, 5 em. T√≠nh c√°c t·ªâ s·ªë l∆∞·ª£ng gi√°c\\nc·ªßa m·ªói g√≥c nh·ªçn. D√πng th∆∞·ªõc ƒëo g√≥c ƒë·ªÖ ƒëo c√°c g√≥c nh·ªçn. Ki·ªÉm tra l·∫°i c√°c k·∫øt qu·∫£ b·∫±ng\\nm√°y t√≠nh c·∫ßm tay.\\n\\nb=a.sinB =a.cosC; c‚Ç¨=a.sSinC =a.cosB;\\nb =c.tanB = c.cotC; c =b.tanC = b.cotB.\\nL√≠ d·ª• 1. Cho tam gi√°c vu√¥ng c√≥ c·∫°nh huy·ªÅn b·∫±ng 30 em v√† m·ªôt g√≥c nh·ªçn b·∫±ng 22¬∞\\n(H√¨nh 2). T√≠nh x, y (k·∫øt qu·∫£ l√†m tr√≤n ƒë·∫øn h√†ng ph·∫ßn trƒÉm).\\nGi·∫£i\\nTam gi√°c vu√¥ng ƒë√£ cho c√≥ c·∫°nh huy·ªÅn b·∫±ng 30 cm. x\\nC·∫°nh g√≥c vu√¥ng x c√≥ g√≥c k√™ bƒÉng 22¬∞ n√™n ta c√≥: ≈∏\\nx=30.cos22¬∞ + 27,82 (cm).\\nC·∫°nh g√≥c vu√¥ng y c√≥ g√≥c ƒë√¥i b·∫±ng 22¬∞ n√™n ta c√≥: mm\\ny=30.. sin22¬∞ 11,24 (em). H√¨nh 2\\n\\nT·ªâ s·ªë l∆∞·ª£ng gi√°c c·ªßa c√°c g√≥c nh·ªçn ƒë·∫∑c bi·ªát (g√≥c 30¬∞, 459, 60¬∞)\\n\\n√ä; a) Cho tam gi√°c ABC vu√¥ng c√¢n CN M\\nt·∫°i A c√≥ c·∫°nh g√≥c vu√¥ng bƒÉng a /\\n(H√¨nh 6a). T√≠nh ƒë·ªô ƒë√†i c·∫°nh huy·ªÅn BC :\\ntheo a, r·ªìi t√≠nh c√°c t·ªâ s·ªë l∆∞·ª£ng gi√°c  a : ·∫¶\\nc·ªßa g√≥c 45‚Äù.\\n\\nb) Cho tam gi√°c ƒë·ªÅu MNP c√≥ c·∫°nh\\nb·∫±ng a (H√¨nh √≥b). T√≠nh ƒë·ªô ƒë√†i  ∆ë M b\\nƒë∆∞·ªùng cao MH theoa r·ªìi t√≠nh c√°ctis√≥ ‚Äî . C√Å 5 tr 5 _\\nl∆∞·ª£ng gi√°c c·ªßa g√≥c 30¬∞ v√† g√≥c 60¬∞. 8) `. b)\\nT·ª´ k·∫øt qu·∫£ c·ªßa ·∫æ%, ta c√≥ b·∫£ng t·ªâ s·ªë l∆∞·ª£ng gi√°c c·ªßa c√°c g√≥c 30¬∞, 45¬∞, 60¬∞ nh∆∞ sau:\\nB·∫£ng (√Ø s·ªë l∆∞·ª£ng gi√°c c·ªßa c√°c g√≥c nh·ªçn ƒë·∫∑c bi·ªát\\n2 2 2\\ne4 2 2 2\\n3\\n√ë, 3\\nVi d·ª• 2. T·ªânh gi√° tr·ªã c·ªßa bi·ªÉu th·ª©c P=S U CC ƒê·ªÇ,\\ntan 45¬∞\\nGi·∫£i\\n11\\nsin30¬∞.ceos6020_ 2\\'2 _ 1\\nTac√≥P=‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî=S·∫±‚Äú=~.\\ntan45¬∞ L4\\nTh·ª±c h√†nh 2. T√≠nh gi√° tr·ªã c·ªßa c√°c bi√™u th·ª©c sau:\\n2cos 45¬∞\\n3) A=‚Äú‚Äú=‚Äî-+3tan30¬∞; ·∫†\\n2sin√≥0¬∞\\nb)B= ‚Äî cot 457.\\nV·∫≠n d·ª•ng 2. T√¨m chi√™u cao c·ªßa th√°p canh : M\\ntrong H√¨nh 7 (k·∫øt qu·∫£ l√†m tr√≤n ƒë·∫øn h√†ng\\nph·∫ßn trƒÉm). ,\\nL·ªùi ‚ÄúƒÉ\\n\\n2. T·ªà S·ªê L∆Ø·ª¢NG GI√ÅC C·ª¶A HAI G√ìC PH·ª§ NHAU\\n√î NG√É aayyaysa B\\n90¬∞ - ≈ì trong H√¨nh 8 theo a, b, c. L2\\n^ ^ ~^ ^ ^ IS‚Äú\\nb) So s√°nh sin B v√† cosC, cos B v√† sinC, tan B v√† ‚Ç¨ ·∫°\\ncotC, tanC v√† cot B.\\nL·ªä ƒë/\\nA b C\\nH√¨nh ¬ß\\nHai g√≥c ƒë∆∞·ª£c g·ªçi l√† ph·ª• nhau n·∫øu ch√∫ng c√≥ t·ªïng b·∫±ng 90¬∞. Nh∆∞ v·∫≠y, g√≥c ph·ª• c·ªßa\\ng√≥c nh·ªçn ≈ì l√† g√≥c (90¬∞ ‚Äî ≈ì).\\nT·ª´·∫©·ªî), ta c√≥ c√°c ƒë·∫≥ng th·ª©c gi·ªØa t·ªâ s·ªë l∆∞·ª£ng gi√°c c·ªßa hai g√≥c ph·ª• nhau nh∆∞ sau:\\nXNK v√† ni e ph·ª• nhau th√¨ sin g√≥c n√†y b·∫±ng c√¥sin g√≥c kia, tang g√≥c n√†y b·∫±ng c√¥tang\\ng√≥c kia. .‚Äî≈ì.\\nsin(90¬∞ ‚Äî ≈ì) = eos ≈ì; . ≈°(90¬∞ ‚Äî 0) = sing,,\\ntan(90¬∞‚Äî g) = coto; (90¬∞~g)=tano....\\nCJi √Ω: T·ª´ nay khi vi·∫øt c√°c t·ªâ s√¥ l∆∞·ª£ng gi√°c c·ªßa m·ªôt g√≥c nh·ªçn trong tam gi√°c, ta c√≥ th√™\\nvi·∫øt sin A thay cho sinA.\\nV√≠ d·ª• 3. So s√°nh:\\na) sin25‚Äù v√† cos6S¬∞; b) cos25‚Äù v√† sin6S¬∞‚Äù;\\n¬©) tan25‚Äù v√† eot65‚Äú; ƒë) cot25‚Äù v√† tan√≥S‚Äù.\\nGi·∫£i\\nTa c√≥:\\na) sin25‚Äù = cos(90‚Äù ‚Äî 25‚Äù) = cos65‚Äù: b) cos25‚Äù = sin(90¬∞ - 25‚Äù) = sin65¬∞;\\ne) tan25¬∞ = cot(90¬∞ - 25‚Äù) = cot65¬∞; ƒë) cot25¬∞ = tan(90¬∞ ‚Äî 25‚Äù) = tan65¬∞.\\nTh·ª±c h√†nh 3.\\n\\nH√¨nh 4\\n12. Cho tam gi√°c ABC c√≥ ba ƒë·ªânh n·∫±m tr√™n ƒë∆∞·ªùng tr√≤n (O) v√† AH l√† ƒë∆∞·ªùng cao.\\nƒê∆∞·ªùng th·∫≥ng AO c·∫Øt ƒë∆∞·ªùng tr√≤n (O) t·∫°i ƒëi·ªÉm th·ª© hai D. Ch·ª©ng minh r·∫±ng:\\na) AC vu√¥ng g√≥c v·ªõi DC;\\nb) ABC = ADC;\\nc)AB. AC=AH. AD.\\n\\nB√ÄI T·∫¨P T·ª∞ LU·∫¨N\\nTrong c√°c b√†i t·∫≠p d∆∞·ªõi ƒë√¢y, n·∫øu kh√¥ng n√≥i g√¨ th√™m th√¨ l√†m tr√≤n k·∫øt qu·∫£ ƒë·∫øn h√†ng\\nph·∫ßn m∆∞·ªùi ho·∫∑c ƒë·∫øn ph√∫!.\\n9. T√¨m s·ªë ƒëo g√≥c ≈ì bi·∫øt r·∫±ng:\\na) san≈ì=0,25;  b)cos≈ì=0,75; c) tan∆°≈ì = l; ƒë) cot≈ì =2.\\n10. Cho tam gi√°c ABC vu√¥ng t·∫°i A c√≥ AB = 18 em, AC = 24 em. T√≠nh c√°c t·ªâ s·ªë l∆∞·ª£ng gi√°c\\nc·ªßa g√≥c B, t·ª´ ƒë√≥ suy ra c√°c t·ªâ s·ªë l∆∞·ª£ng gi√°c c·ªßa g√≥c C.\\n11. Cho tam gi√°c ABC vu√¥ng t·∫°i A. Ch·ª©ng minh r·∫±ng . H√Ä\\nAB sinC\\n12. Cho g√≥c nh·ªçn ≈ì bi·∫øt sin ≈ì = 0,8. T√≠nh cos ≈ì, tan ≈ì v√† cot ≈ì.\\n13. T√≠nh gi√° tr·ªã c·ªßa bi·ªÉu th·ª©c:\\n8) A=4‚Äîsin?45¬∞ + 2 cos?60¬∞ ‚Äî 3 cot? 459:\\nb) B =tan45¬∞. cos30¬∞. cot30‚Äù;\\nc) C=sin 15 + sin75‚Äù ‚Äî cos I5‚Äù ‚Äî cos75¬∞ + sin30!.\\n14. Cho tam gi√°c OPQ vu√¥ng t·∫°i O c√≥ P = 39‚Äù v√† PQ = 10 em. H√£y gi·∫£i tam gi√°c vu√¥ng OPQ.\\nM\\n¬ª\\n15. Hai ƒëi·ªám P v√† Q c√°ch nhau 203 m v√† thƒÉng h√†ng\\nv·ªõi ch√¢n c·ªßa m·ªôt to√† th√°p (H√¨nh 3). T·ª´ ƒë√≠nh c·ªßa\\n‚ÅÑ to√† th√°p ƒë√≥, m·ªôt ng∆∞·ªùi nh√¨n th√¢y hai ƒëi·ªÉm P, Q\\nv·ªõi hai g√≥c nghi√™ng xu·ªëng l·∫ßn l∆∞·ª£t l√† 38¬∞ v√† 44/.\\nT√≠nh chi·ªÅu cao c·ªßa to√† th√°p (k·∫øt qu·∫£ l√†m tr√≤n\\n` ƒë·∫øn h√†ng ƒë∆°n v·ªã c·ªßa m√©t).\\nP203mQ N\\nH√¨nh 3\\n` .√° h ` h·ªü) | \"', additional_kwargs={}, response_metadata={}), HumanMessage(content='H√£y cho t√¥i bi·∫øt h·ªá th·ª©c l∆∞·ª£ng trong tam gi√°c vu√¥ng?', additional_kwargs={}, response_metadata={})]\n",
      "Question: H√£y cho t√¥i bi·∫øt h·ªá th·ª©c l∆∞·ª£ng trong tam gi√°c vu√¥ng?\n",
      "Answer: H·ªá th·ª©c l∆∞·ª£ng trong tam gi√°c vu√¥ng bao g·ªìm c√°c c√¥ng th·ª©c li√™n quan ƒë·∫øn c·∫°nh v√† g√≥c, c·ª• th·ªÉ nh∆∞ sau:\n",
      "\n",
      "1. C·∫°nh g√≥c vu√¥ng b·∫±ng c·∫°nh huy·ªÅn nh√¢n v·ªõi sin g√≥c ƒë·ªëi:\n",
      "   - \\( AB = c \\cdot \\sin \\angle A \\)\n",
      "\n",
      "2. C·∫°nh g√≥c vu√¥ng b·∫±ng c·∫°nh huy·ªÅn nh√¢n v·ªõi cos g√≥c k·ªÅ:\n",
      "   - \\( AC = c \\cdot \\cos \\angle A \\)\n",
      "\n",
      "3. C·∫°nh g√≥c vu√¥ng b·∫±ng c·∫°nh g√≥c vu√¥ng c√≤n l·∫°i nh√¢n v·ªõi tang g√≥c ƒë·ªëi:\n",
      "   - \\( AB = AC \\cdot \\tan \\angle A \\)\n",
      "\n",
      "4. C·∫°nh g√≥c vu√¥ng b·∫±ng c·∫°nh g√≥c vu√¥ng c√≤n l·∫°i nh√¢n v·ªõi c√¥tang g√≥c k·ªÅ:\n",
      "   - \\( AC = AB \\cdot \\cot \\angle A \\)\n",
      "\n",
      "Ngo√†i ra, theo ƒë·ªãnh l√Ω Pythagore, t·ªïng b√¨nh ph∆∞∆°ng c·ªßa hai c·∫°nh g√≥c vu√¥ng b·∫±ng b√¨nh ph∆∞∆°ng c·ªßa c·∫°nh huy·ªÅn:\n",
      "   - \\( AB^2 + AC^2 = BC^2 \\)\n",
      "\n",
      "C√°c t·ªâ s·ªë l∆∞·ª£ng gi√°c c·ªßa g√≥c nh·ªçn trong tam gi√°c vu√¥ng c≈©ng gi√∫p t√≠nh to√°n kho·∫£ng c√°ch gi·ªØa hai ƒëi·ªÉm c√°ch xa nhau.\n"
     ]
    }
   ],
   "source": [
    "# Initialize chat history for conversation\n",
    "chat_history = []\n",
    "# Example usage\n",
    "# Replace with your actual question\n",
    "question = \"H√£y cho t√¥i bi·∫øt h·ªá th·ª©c l∆∞·ª£ng trong tam gi√°c vu√¥ng?\"  # \"What is the main content of this document?\"\n",
    "answer = answer_question(vector_store, question, chat_history)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
